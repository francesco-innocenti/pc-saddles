{"cells":[{"cell_type":"markdown","metadata":{"id":"1b9WyJE3D3Il"},"source":["# Hessian Analysis of DLNs\n","\n","This notebook compares the MSE loss and energy Hessian at the origin for deep linear networks (DLNs) on different datasets and architectures.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tiGklA_e9Abi"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"XwkMH9mjx_dc"},"outputs":[],"source":["#@title Installations\n","\n","\n","%%capture\n","!sudo apt install nvidia-utils-515\n","!pip install -U kaleido\n","!pip install gif==3.0.0\n","\n","!pip install git+https://github.com/greydanus/mnist1d.git@master"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"tC-fTIbPAlIk"},"outputs":[],"source":["#@title Imports\n","\n","\n","import os\n","import random\n","import subprocess\n","import numpy as np\n","from typing import Tuple, List, Dict, Optional\n","\n","from mnist1d.data import get_dataset, get_dataset_args\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn.utils import vector_to_parameters\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms\n","\n","from jax import jacfwd, jacrev\n","from jax.numpy.linalg import eigh\n","\n","import gif\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LogNorm\n","import plotly.graph_objs as go\n","import plotly.express as px\n","from plotly.colors import hex_to_rgb\n","from plotly.express.colors import sample_colorscale\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rlbd0rQGqVM","cellView":"form"},"outputs":[],"source":["#@title Config\n","\n","DATASETS = [\"toy_gaussian\", \"MNIST\", \"MNIST-1D\"]\n","N_HIDDEN_WIDTHS = {\n","    \"toy_gaussian\": [\n","        [1, 10],\n","        [2, 5],\n","        [3, 4],\n","        [4, 4]\n","    ],\n","    \"MNIST\": [\n","        [1, 10],\n","        [2, 10],\n","        [3, 5],\n","        [4, 5]\n","    ],\n","    \"MNIST-1D\": [\n","        [1, 100],\n","        [2, 50],\n","        [3, 10],\n","        [4, 5],\n","    ]\n","}\n","INIT_TYPES = {\n","    1: [\"origin\"],\n","    2: [\"origin\"],\n","    3: [\"origin\", \"other_saddle\"],\n","    4: [\"origin\", \"other_saddle\"],\n","}\n","N_SEEDS = 1\n","RESULTS_DIR = \"results\"\n","\n","# toy dataset\n","DATA_MEAN, DATA_STD = 1., 0.1\n","BATCH_SIZE = 64\n","\n","# PC hyperparameters\n","N_ITERS = 50\n","DT = 0.1\n","\n","# landscape plotting\n","DOMAINS = [2, 1, 5e-1, 1e-1, 5e-2]\n","SAMPLING_RESOLUTION = 30\n","COLORSCALE = \"RdBu_r\"\n","PLOT_ITERS = [0, 1, 2, 3, 4, 5, 10, 20, 50, 100, 200, 500, 1000]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ATq_cOK_Ao8t"},"outputs":[],"source":["#@title Utils\n","\n","\n","def setup_experiment(results_dir, dataset, data_dim, n_hidden, width, init_type, seed):\n","    print(\n","f\"\"\"\n","Starting Hessian analysis with experiment configuration:\n","\n","  Dataset: {dataset}\n","  Data dim: {data_dim}\n","  N hidden: {n_hidden}\n","  Width: {width}\n","  Init type: {init_type}\n","  Seed: {seed}\n","\"\"\"\n",")\n","    if dataset == \"toy_gaussian\":\n","        experiment_dir = os.path.join(\n","            results_dir,\n","            dataset,\n","            f\"data_dim_{data_dim}\",\n","            f\"n_hidden_{n_hidden}\",\n","            f\"width_{width}\",\n","            f\"{init_type}_init\",\n","            str(seed)\n","        )\n","    else:\n","        experiment_dir = os.path.join(\n","            results_dir,\n","            dataset,\n","            f\"n_hidden_{n_hidden}\",\n","            f\"width_{width}\",\n","            f\"{init_type}_init\",\n","            str(seed)\n","        )\n","    return experiment_dir\n","\n","\n","def set_seed(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","\n","def get_device():\n","    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def get_fc_network(input_dim, n_hidden, width, act_fn, output_dim, bias=False):\n","    layers = []\n","    for n in range(n_hidden):\n","        n_input = input_dim if n == 0 else width\n","        if act_fn == \"linear\":\n","            hidden_layer = nn.Sequential(nn.Linear(n_input, width, bias=bias))\n","        elif act_fn == \"tanh\":\n","            hidden_layer = nn.Sequential(\n","                nn.Linear(n_input, width, bias=bias),\n","                nn.Tanh()\n","            )\n","        elif act_fn == \"relu\":\n","            hidden_layer = nn.Sequential(\n","                nn.Linear(n_input, width, bias=bias),\n","                nn.ReLU(inplace=True)\n","            )\n","        layers.append(hidden_layer)\n","\n","    output_layer = nn.Sequential(nn.Linear(width, output_dim, bias=bias))\n","    layers.append(output_layer)\n","    network = nn.Sequential(*layers)\n","    return network\n","\n","\n","def zero_weights(module):\n","    if isinstance(module, nn.Linear):\n","        nn.init.normal_(module.weight, mean=0., std=0.)\n","\n","\n","def init_weights(model, init_type):\n","    if init_type == \"origin\":\n","        model.network.apply(zero_weights)\n","    else:\n","        n_layers = len(model.network)\n","        for l in range(n_layers):\n","            # zero weights all layers except penultimate\n","            if l+1 != n_layers-1:\n","                model.network[l].apply(zero_weights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"kfz2BdzNAg79"},"outputs":[],"source":["#@title Datasets\n","\n","\n","def get_dataset_sample(dataset_id, data_dim, n_hidden):\n","    if dataset_id == \"toy_gaussian\":\n","        input = np.random.normal(\n","            loc=DATA_MEAN,\n","            scale=DATA_STD,\n","            size=(data_dim, BATCH_SIZE)\n","        )\n","        target = -input\n","        if data_dim == 3 and n_hidden == 4:\n","            y2 = np.random.normal(\n","                loc=DATA_MEAN,\n","                scale=DATA_STD,\n","                size=BATCH_SIZE\n","            )\n","            target[1, :] = y2\n","    elif dataset_id == \"MNIST\":\n","        input, target = get_MNIST_sample()\n","    elif dataset_id == \"MNIST-1D\":\n","        input, target = get_MNIST_1d_sample()\n","    else:\n","        raise ValueError(\"Invalid dataset ID. Options are 'MNIST' and 'toy_gaussian'\")\n","\n","    return input, target\n","\n","\n","def get_MNIST_1d_sample():\n","    args = get_dataset_args()\n","    dataset = get_dataset(\n","        args,\n","        path=f\"./mnist1d_data.pkl\",\n","        download=False,\n","        regenerate=False\n","    )\n","    train_data = TensorDataset(\n","        torch.Tensor(dataset[\"x\"]),\n","        torch.Tensor(one_hot(dataset[\"y\"]))\n","    )\n","    data_loader = DataLoader(\n","        dataset=train_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        drop_last=True\n","    )\n","    img_batch, label_batch = next(iter(data_loader))\n","    return img_batch.numpy().T, label_batch.numpy().T\n","\n","\n","def get_data_dim(dataset, n_hidden):\n","    if dataset != \"toy_gaussian\":\n","        data_dim = None\n","    else:\n","        if n_hidden > 2:\n","            data_dim = 3\n","        else:\n","            data_dim = 2\n","\n","    return data_dim\n","\n","\n","def get_MNIST_sample():\n","    train_data = MNIST(train=True)\n","    train_loader = DataLoader(\n","        dataset=train_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        drop_last=True\n","    )\n","    img_batch, label_batch = next(iter(train_loader))\n","    return img_batch.numpy().T, label_batch.numpy().T\n","\n","\n","class MNIST(datasets.MNIST):\n","    def __init__(self, train, normalise=True, save_dir=\"./data\"):\n","        if normalise:\n","            transform = transforms.Compose(\n","                [\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(\n","                        mean=(0.1307), std=(0.3081)\n","                    )\n","                ]\n","            )\n","        else:\n","            transform = transforms.Compose([transforms.ToTensor()])\n","        super().__init__(save_dir, download=True, train=train, transform=transform)\n","\n","    def __getitem__(self, index):\n","        img, label = super().__getitem__(index)\n","        img = torch.flatten(img)\n","        label = one_hot(label)\n","        return img, label\n","\n","\n","def one_hot(labels, n_classes=10):\n","    arr = torch.eye(n_classes)\n","    return arr[labels]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"IxZmNRPguIue"},"outputs":[],"source":["#@title Models\n","\n","\n","class BPN(nn.Module):\n","    def __init__(self, network):\n","        super(BPN, self).__init__()\n","        self.network = network\n","\n","    def forward(self, x):\n","        x = self.network(x)\n","        return x\n","\n","    def get_weights(self):\n","        weights = []\n","        for param in self.network.parameters():\n","            if len(param.shape) > 1:\n","                weights.append(param.cpu().detach().numpy())\n","        return weights\n","\n","\n","\n","class PCN(object):\n","    def __init__(self, network, dt, device=\"cpu\"):\n","        self.network = network.to(device)\n","        self.n_layers = len(self.network)\n","        self.n_nodes = self.n_layers + 1\n","        self.dt = dt\n","        self.n_params = sum(\n","            p.numel() for p in network.parameters() if p.requires_grad\n","        )\n","        self.device = device\n","\n","    def reset(self):\n","        self.zero_grad()\n","        self.preds = [None] * self.n_nodes\n","        self.errs = [None] * self.n_nodes\n","        self.xs = [None] * self.n_nodes\n","\n","    def reset_xs(self, prior, init_std):\n","        self.set_prior(prior)\n","        self.propagate_xs()\n","        for l in range(self.n_layers):\n","            self.xs[l] = torch.empty(self.xs[l].shape).normal_(\n","                mean=0,\n","                std=init_std\n","            ).to(self.device)\n","\n","    def set_obs(self, obs):\n","        self.xs[-1] = obs.clone()\n","\n","    def set_prior(self, prior):\n","        self.xs[0] = prior.clone()\n","\n","    def forward(self, x):\n","        return self.network(x)\n","\n","    def propagate_xs(self):\n","        for l in range(1, self.n_layers):\n","            self.xs[l] = self.network[l - 1](self.xs[l - 1])\n","\n","    def infer_train(\n","            self,\n","            obs,\n","            prior,\n","            n_iters,\n","            record_grad_norms=False,\n","        ):\n","        self.reset()\n","        self.set_prior(prior)\n","        self.propagate_xs()\n","        self.set_obs(obs)\n","\n","        if record_grad_norms:\n","            grad_norms_iters = [np.zeros(n_iters) for p in range(len(self.network)*2)]\n","\n","        dt = self.dt\n","        tot_energy_iters = []\n","        for t in range(n_iters):\n","            self.network.zero_grad()\n","            self.preds[-1] = self.network[self.n_layers - 1](self.xs[self.n_layers - 1])\n","            self.errs[-1] = self.xs[-1] - self.preds[-1]\n","\n","            for l in reversed(range(1, self.n_layers)):\n","                self.preds[l] = self.network[l - 1](self.xs[l - 1])\n","                self.errs[l] = self.xs[l] - self.preds[l]\n","                _, epsdfdx = torch.autograd.functional.vjp(\n","                    self.network[l],\n","                    self.xs[l],\n","                    self.errs[l + 1]\n","                )\n","                with torch.no_grad():\n","                    dx = epsdfdx - self.errs[l]\n","                    self.xs[l] = self.xs[l] + self.dt * dx\n","\n","            tot_energy_iters.append(self.compute_tot_energy())\n","            if t > 0 and tot_energy_iters[t] >= tot_energy_iters[t-1] and self.dt > 0.025:\n","                self.dt /= 2\n","                if self.dt <= 0.025:\n","                    self.dt = dt\n","                    break\n","\n","            if (t+1) != n_iters:\n","                self.clear_grads()\n","\n","        if record_grad_norms:\n","            self.set_grads(\n","                grad_norms_iters=grad_norms_iters,\n","                t=t\n","            )\n","        else:\n","            self.set_grads()\n","\n","        if record_grad_norms:\n","            return tot_energy_iters, grad_norms_iters\n","        else:\n","            return tot_energy_iters\n","\n","    def infer_test(\n","            self,\n","            obs,\n","            prior,\n","            n_iters,\n","            update_prior=True,\n","            update_obs=False,\n","            init_std=0.05,\n","        ):\n","\n","        self.reset()\n","        self.reset_xs(prior, init_std)\n","        if not update_prior:\n","            self.set_prior(prior)\n","        self.set_obs(obs)\n","\n","        for t in range(n_iters):\n","            self.network.zero_grad()\n","            self.preds[-1] = self.network[self.n_layers - 1](self.xs[self.n_layers - 1])\n","            self.errs[-1] = self.xs[-1] - self.preds[-1]\n","\n","            if update_obs:\n","                with torch.no_grad():\n","                    self.xs[-1] = self.xs[-1] + self.dt * (- self.errs[-1])\n","\n","            for l in reversed(range(1, self.n_layers)):\n","                self.preds[l] = self.network[l - 1](self.xs[l - 1])\n","                self.errs[l] = self.xs[l] - self.preds[l]\n","                _, epsdfdx = torch.autograd.functional.vjp(\n","                    self.network[l],\n","                    self.xs[l],\n","                    self.errs[l + 1]\n","                )\n","                with torch.no_grad():\n","                    dx = epsdfdx - self.errs[l]\n","                    self.xs[l] = self.xs[l] + self.dt * dx\n","\n","            if update_prior:\n","                _, epsdfdx = torch.autograd.functional.vjp(\n","                    self.network[0],\n","                    self.xs[0],\n","                    self.errs[1]\n","                )\n","                with torch.no_grad():\n","                    self.xs[0] = self.xs[0] + self.dt * epsdfdx\n","\n","            if (t+1) != n_iters:\n","                self.clear_grads()\n","\n","        if update_prior:\n","            return self.xs[0]\n","        elif update_obs:\n","            return self.xs[-1]\n","\n","    def set_grads(self, grad_norms_iters=None, t=None):\n","        n = 0\n","        for l in range(self.n_layers):\n","            for i, param in enumerate(self.network[l].parameters()):\n","                dparam = torch.autograd.grad(\n","                    self.preds[l + 1],\n","                    param,\n","                    - self.errs[l + 1],\n","                    allow_unused=True,\n","                    retain_graph=True\n","                )[0]\n","                param.grad = dparam.clone()\n","                if grad_norms_iters is not None:\n","                    is_even = (i+1) % 2 == 0\n","                    dparam_norm = vector_norm(dparam) if is_even else matrix_norm(dparam)\n","                    grad_norms_iters[n][t] = dparam_norm.item()\n","                    n += 1\n","\n","    def zero_grad(self):\n","        self.network.zero_grad()\n","\n","    def clear_grads(self):\n","        with torch.no_grad():\n","            for l in range(1, self.n_nodes):\n","                self.preds[l] = self.preds[l].clone()\n","                self.errs[l] = self.errs[l].clone()\n","                self.xs[l] = self.xs[l].clone()\n","\n","    def save_weights(self, path):\n","        torch.save(self.network.state_dict(), path)\n","\n","    def load_weights(self, path):\n","        self.network.load_state_dict(torch.load(path))\n","\n","    def get_weights(self):\n","        weights = []\n","        for param in self.network.parameters():\n","            if len(param.shape) > 1:\n","                weights.append(param.cpu().detach().numpy())\n","        return weights\n","\n","    def compute_tot_energy(self):\n","        energy = 0.\n","        for err in self.errs:\n","            if err is not None:\n","                energy += (err**2).sum()\n","        return energy.item()\n","\n","    def parameters(self):\n","        return self.network.parameters()\n","\n","    def __str__(self):\n","        return f\"PCN(\\n{self.network}\\n\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FqQeB0TpivZw"},"outputs":[],"source":["#@title Weight manipulation\n","# Adapted from https://github.com/tomgoldstein/loss-landscape/blob/master/net_plotter.py\n","\n","\n","def get_weights(net):\n","    \"\"\" Extract parameters from net, and return a list of tensors\"\"\"\n","    return [p.data for p in net.parameters()]\n","\n","\n","def get_random_weights(weights, device='cpu'):\n","    \"\"\"\n","        Produce a random direction that is a list of random Gaussian tensors\n","        with the same shape as the network's weights, so one direction entry per weight.\n","    \"\"\"\n","    return [torch.randn(w.size()).to(device) for w in weights]\n","\n","\n","def normalize_direction(direction, weights, norm='filter'):\n","    \"\"\"\n","        Rescale the direction so that it has similar norm as their corresponding\n","        model in different levels.\n","\n","        Args:\n","          direction: a variables of the random direction for one layer\n","          weights: a variable of the original model for one layer\n","          norm: normalization method, 'filter' | 'layer' | 'weight'\n","    \"\"\"\n","    if norm == 'filter':\n","        # Rescale the filters (weights in group) in 'direction' so that each\n","        # filter has the same norm as its corresponding filter in 'weights'.\n","        for d, w in zip(direction, weights):\n","            d.mul_(w.norm()/(d.norm() + 1e-10))\n","    elif norm == 'layer':\n","        # Rescale the layer variables in the direction so that each layer has\n","        # the same norm as the layer variables in weights.\n","        direction.mul_(weights.norm()/direction.norm())\n","    elif norm == 'weight':\n","        # Rescale the entries in the direction so that each entry has the same\n","        # scale as the corresponding weight.\n","        direction.mul_(weights)\n","    elif norm == 'dfilter':\n","        # Rescale the entries in the direction so that each filter direction\n","        # has the unit norm.\n","        for d in direction:\n","            d.div_(d.norm() + 1e-10)\n","    elif norm == 'dlayer':\n","        # Rescale the entries in the direction so that each layer direction has\n","        # the unit norm.\n","        direction.div_(direction.norm())\n","\n","\n","def normalize_directions_for_weights(direction, weights, norm='filter', ignore='biasbn'):\n","    \"\"\"\n","        The normalization scales the direction entries according to the entries of weights.\n","    \"\"\"\n","    assert(len(direction) == len(weights))\n","    for d, w in zip(direction, weights):\n","        if d.dim() <= 1:\n","            if ignore == 'biasbn':\n","                d.fill_(0) # ignore directions for weights with 1 dimension\n","            else:\n","                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n","        else:\n","            normalize_direction(d, w, norm)\n","\n","\n","def create_random_weight_direction(net, device='cpu', ignore='biasbn', norm='filter'):\n","    \"\"\"\n","        Setup a random (normalized) direction with the same dimension as\n","        the weights.\n","        Args:\n","          net: the given trained model\n","          ignore: 'biasbn', ignore biases and BN parameters.\n","          norm: direction normalization method, including\n","                'filter\" | 'layer' | 'weight' | 'dlayer' | 'dfilter'\n","        Returns:\n","          direction: a random direction with the same dimension as weights.\n","    \"\"\"\n","\n","    # random direction\n","    weights = get_weights(net) # a list of parameters.\n","    direction = get_random_weights(weights, device)\n","    normalize_directions_for_weights(direction, weights, norm, ignore)\n","    return direction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"eMJJ1NyknHyU"},"outputs":[],"source":["#@title Plotting\n","\n","\n","@gif.frame\n","def plot_hessian_matrix(hessian_matrix, save_path, log=False, title=None):\n","    fig, ax = plt.subplots()\n","    if log:\n","        heatmap = ax.imshow(\n","            X=hessian_matrix,\n","            cmap=\"bwr\",\n","            norm=LogNorm()\n","        )\n","    else:\n","        heatmap = ax.imshow(\n","            X=hessian_matrix,\n","            cmap=\"bwr\",\n","            vmin=-1,\n","            vmax=1\n","        )\n","    cbar = fig.colorbar(heatmap, ax=ax, location=\"right\", ticks=[-1, 0, 1])\n","    cbar.ax.tick_params(labelsize=25)\n","\n","    if len(hessian_matrix) > 10:\n","        ax.axes.get_xaxis().set_visible(False)\n","        ax.axes.get_yaxis().set_visible(False)\n","    else:\n","        ticks = np.arange(len(hessian_matrix), dtype=int)\n","        ax.set_xticks(ticks)\n","        ax.set_yticks(ticks)\n","        ax.set_xticklabels(ticks+1)\n","        ax.set_yticklabels(ticks+1)\n","\n","    if title is not None:\n","        plt.title(title, fontsize=20)\n","    fig.savefig(save_path)\n","    return fig\n","\n","\n","@gif.frame\n","def plot_hessian_eigenvalues(eigenvalues, save_path, title=None):\n","    fig = go.Figure(\n","        data=go.Histogram(\n","            x=eigenvalues,\n","            histnorm=\"probability\",\n","            xbins=dict(size=0.2),\n","            marker_color=\"#FF7F0E\"\n","        )\n","    )\n","    fig.update_layout(\n","        height=325,\n","        width=500,\n","        title=dict(\n","            text=title if title is not None else \"\",\n","            y=0.75,\n","            x=0.5,\n","            xanchor=\"center\",\n","            yanchor=\"top\"\n","        ),\n","        xaxis=dict(title=\"Hessian eigenvalue\"),\n","        yaxis=dict(\n","            title=f\"Density (log)\",\n","            type=\"log\",\n","            exponentformat=\"power\",\n","            dtick=1\n","        ),\n","        font=dict(size=16)\n","    )\n","    fig.write_image(save_path)\n","    return fig\n","\n","\n","def plot_loss_and_energy_hessian_eigenvals(hessian_eigenvals: List, n_hidden: str, dataset: str, save_path: str) -> None:\n","    fig = go.Figure()\n","    names = [\"loss\", \"energy (numeric)\", \"energy (theory)\"]\n","    colors = [\"#EF553B\", \"#636EFA\", \"rgba(0,0,0,0)\"]\n","\n","    n_loss_bins = 5 if n_hidden == 1 and dataset != \"toy_gaussian\" else 10\n","    n_energy_bins = 30 if n_hidden == 1 and dataset != \"toy_gaussian\" else 10\n","    for eigenval, name, color in zip(hessian_eigenvals, names, colors):\n","        fig.add_trace(\n","            go.Histogram(\n","                x=eigenval,\n","                histnorm=\"probability\",\n","                nbinsx=n_loss_bins if name == \"loss\" else n_energy_bins,\n","                name=name,\n","                marker=dict(\n","                    color=color,\n","                    line=dict(\n","                        color=\"black\",\n","                        width=2 if \"theory\" in name else 0\n","                    )\n","                ),\n","            )\n","        )\n","\n","    fig.update_layout(\n","        barmode=\"overlay\",\n","        height=360,\n","        width=525,\n","        xaxis=dict(title=\"Hessian eigenvalue\"),\n","        yaxis=dict(\n","            title=f\"Density (log)\",\n","            type=\"log\",\n","            exponentformat=\"power\",\n","            dtick=1,\n","        ),\n","        font=dict(size=18)\n","    )\n","    fig.update_layout(\n","        legend=dict(\n","            yanchor=\"top\",\n","            y=0.99,\n","            xanchor=\"left\",\n","            x=0.01,\n","            font=dict(size=16)\n","        )\n","    )\n","    fig.update_traces(opacity=0.75)\n","    fig.write_image(save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_MZw5dTuB6TA"},"outputs":[],"source":["#@title Hessian utils\n","\n","\n","def compute_hessian(f):\n","    return jacfwd(jacrev(f))\n","\n","\n","def mse_loss_fun(Ws, X, Y):\n","    n_hidden = len(Ws)-1\n","    if n_hidden == 1:\n","        loss = ( 0.5*(Y - Ws[1]@Ws[0]@X)**2 ).mean()\n","    elif n_hidden == 2:\n","        loss = ( 0.5*(Y - Ws[2]@Ws[1]@Ws[0]@X)**2 ).mean()\n","    elif n_hidden == 3:\n","        loss = ( 0.5*(Y - Ws[3]@Ws[2]@Ws[1]@Ws[0]@X)**2 ).mean()\n","    elif n_hidden == 4:\n","        loss = ( 0.5*(Y - Ws[4]@Ws[3]@Ws[2]@Ws[1]@Ws[0]@X)**2 ).mean()\n","    return loss\n","\n","\n","def energy_fun(Ws, Xs, n_iters, dt):\n","    n_hidden = len(Ws)-1\n","    if n_hidden == 1:\n","        # initialisation\n","        Z1 = Xs[1]\n","        e2 = Xs[2] - Ws[1]@Z1\n","        e1 = Z1 - Ws[0]@Xs[0]\n","\n","        # iterative inference\n","        for t in range(n_iters):\n","            dZ1 = e1 - (e2.T@Ws[1]).T\n","            Z1 += - dZ1 * dt\n","\n","            e2 = Xs[2] - Ws[1]@Z1\n","            e1 = Z1 - Ws[0]@Xs[0]\n","\n","        energy = ( (0.5*e1**2).sum() + (0.5*e2**2).sum() ) / (BATCH_SIZE)\n","\n","    elif n_hidden == 2:\n","        # initialisation\n","        Z1, Z2 = Xs[1], Xs[2]\n","        e3 = Xs[3] - Ws[2]@Z2\n","        e2 = Z2 - Ws[1]@Z1\n","        e1 = Z1 - Ws[0]@Xs[0]\n","\n","        # iterative inference\n","        for t in range(n_iters):\n","            dZ1 = e1 - (e2.T@Ws[1]).T\n","            dZ2 = e2 - (e3.T@Ws[2]).T\n","            Z1 += - dZ1 * dt\n","            Z2 += - dZ2 * dt\n","\n","            e3 = Xs[3] - Ws[2]@Z2\n","            e2 = Z2 - Ws[1]@Z1\n","            e1 = Z1 - Ws[0]@Xs[0]\n","\n","        energy = ( (0.5*e1**2).sum() + (0.5*e2**2).sum() + (0.5*e3**2).sum() ) / (BATCH_SIZE)\n","\n","    elif n_hidden == 3:\n","        # initialisation\n","        Z1, Z2, Z3 = Xs[1], Xs[2], Xs[3]\n","        e4 = Xs[4] - Ws[3]@Z3\n","        e3 = Z3 - Ws[2]@Z2\n","        e2 = Z2 - Ws[1]@Z1\n","        e1 = Z1 - Ws[0]@Xs[0]\n","\n","        # iterative inference\n","        for t in range(n_iters):\n","            dZ1 = e1 - (e2.T@Ws[1]).T\n","            dZ2 = e2 - (e3.T@Ws[2]).T\n","            dZ3 = e3 - (e4.T@Ws[3]).T\n","            Z1 += - dZ1 * dt\n","            Z2 += - dZ2 * dt\n","            Z3 += - dZ3 * dt\n","\n","            e4 = Xs[4] - Ws[3]@Z3\n","            e3 = Z3 - Ws[2]@Z2\n","            e2 = Z2 - Ws[1]@Z1\n","            e1 = Z1 - Ws[0]@Xs[0]\n","\n","        energy = ( (0.5*e1**2).sum() + (0.5*e2**2).sum() + (0.5*e3**2).sum() + (0.5*e4**2).sum() ) / (BATCH_SIZE)\n","\n","    elif n_hidden == 4:\n","        # initialisation\n","        Z1, Z2, Z3, Z4 = Xs[1], Xs[2], Xs[3], Xs[4]\n","        e5 = Xs[5] - Ws[4]@Z4\n","        e4 = Z4 - Ws[3]@Z3\n","        e3 = Z3 - Ws[2]@Z2\n","        e2 = Z2 - Ws[1]@Z1\n","        e1 = Z1 - Ws[0]@Xs[0]\n","\n","        # iterative inference\n","        for t in range(n_iters):\n","            dZ1 = e1 - (e2.T@Ws[1]).T\n","            dZ2 = e2 - (e3.T@Ws[2]).T\n","            dZ3 = e3 - (e4.T@Ws[3]).T\n","            dZ4 = e4 - (e5.T@Ws[4]).T\n","            Z1 += - dZ1 * dt\n","            Z2 += - dZ2 * dt\n","            Z3 += - dZ3 * dt\n","            Z4 += - dZ4 * dt\n","\n","            e5 = Xs[5] - Ws[4]@Z4\n","            e4 = Z4 - Ws[3]@Z3\n","            e3 = Z3 - Ws[2]@Z2\n","            e2 = Z2 - Ws[1]@Z1\n","            e1 = Z1 - Ws[0]@Xs[0]\n","\n","        energy = ( (0.5*e1**2).sum() + (0.5*e2**2).sum() + (0.5*e3**2).sum() + (0.5*e4**2).sum() + (0.5*e5**2).sum() ) / (BATCH_SIZE)\n","\n","    return energy\n","\n","\n","def reshape_to_hessian_matrix(hessian, weights):\n","    n_hidden = len(weights)-1\n","    if n_hidden == 1:\n","        N1, N2 = np.prod(weights[0].shape), np.prod(weights[1].shape)\n","        hessian_matrix = np.zeros((N1+N2, N1+N2))\n","\n","        hessian_matrix[:N1, :N1] = hessian[0][0].reshape(N1, N1)\n","        hessian_matrix[:N1, N1:] = hessian[0][1].reshape(N1, N2)\n","        hessian_matrix[N1:, :N1] = hessian[1][0].reshape(N2, N1)\n","        hessian_matrix[N1:, N1:] = hessian[1][1].reshape(N2, N2)\n","\n","    if n_hidden == 2:\n","        N1, N2, N3 = np.prod(weights[0].shape), np.prod(weights[1].shape), np.prod(weights[2].shape)\n","        hessian_matrix = np.zeros((N1+N2+N3, N1+N2+N3))\n","\n","        hessian_matrix[:N1, :N1] = hessian[0][0].reshape(N1, N1)\n","        hessian_matrix[:N1, N1:N1+N2] = hessian[0][1].reshape(N1, N2)\n","        hessian_matrix[:N1, N1+N2:] = hessian[0][2].reshape(N1, N3)\n","\n","        hessian_matrix[N1:N1+N2, :N1] = hessian[1][0].reshape(N2, N1)\n","        hessian_matrix[N1:N1+N2, N1:N1+N2] = hessian[1][1].reshape(N2, N2)\n","        hessian_matrix[N1:N1+N2, N1+N2:] = hessian[1][2].reshape(N2, N3)\n","\n","        hessian_matrix[N1+N2:, :N1] = hessian[2][0].reshape(N3, N1)\n","        hessian_matrix[N1+N2:, N1:N1+N2] = hessian[2][1].reshape(N3, N2)\n","        hessian_matrix[N1+N2:, N1+N2:] = hessian[2][2].reshape(N3, N3)\n","\n","    if n_hidden == 3:\n","        N1, N2, N3, N4 = np.prod(weights[0].shape), np.prod(weights[1].shape), np.prod(weights[2].shape), np.prod(weights[3].shape)\n","        hessian_matrix = np.zeros((N1+N2+N3+N4, N1+N2+N3+N4))\n","\n","        hessian_matrix[:N1, :N1] = hessian[0][0].reshape(N1, N1)\n","        hessian_matrix[:N1, N1:N1+N2] = hessian[0][1].reshape(N1, N2)\n","        hessian_matrix[:N1, N1+N2:N1+N2+N3] = hessian[0][2].reshape(N1, N3)\n","        hessian_matrix[:N1, N1+N2+N3:] = hessian[0][3].reshape(N1, N4)\n","\n","        hessian_matrix[N1:N1+N2, :N1] = hessian[1][0].reshape(N2, N1)\n","        hessian_matrix[N1:N1+N2, N1:N1+N2] = hessian[1][1].reshape(N2, N2)\n","        hessian_matrix[N1:N1+N2, N1+N2:N1+N2+N3] = hessian[1][2].reshape(N2, N3)\n","        hessian_matrix[N1:N1+N2, N1+N2+N3:] = hessian[1][3].reshape(N2, N4)\n","\n","        hessian_matrix[N1+N2:N1+N2+N3, :N1] = hessian[2][0].reshape(N3, N1)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1:N1+N2] = hessian[2][1].reshape(N3, N2)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1+N2:N1+N2+N3] = hessian[2][2].reshape(N3, N3)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1+N2+N3:] = hessian[2][3].reshape(N3, N4)\n","\n","        hessian_matrix[N1+N2+N3:, :N1] = hessian[3][0].reshape(N4, N1)\n","        hessian_matrix[N1+N2+N3:, N1:N1+N2] = hessian[3][1].reshape(N4, N2)\n","        hessian_matrix[N1+N2+N3:, N1+N2:N1+N2+N3] = hessian[3][2].reshape(N4, N3)\n","        hessian_matrix[N1+N2+N3:, N1+N2+N3:] = hessian[3][3].reshape(N4, N4)\n","\n","    if n_hidden == 4:\n","        N1, N2, N3, N4, N5 = np.prod(weights[0].shape), np.prod(weights[1].shape), np.prod(weights[2].shape), np.prod(weights[3].shape), np.prod(weights[4].shape)\n","        hessian_matrix = np.zeros((N1+N2+N3+N4+N5, N1+N2+N3+N4+N5))\n","\n","        hessian_matrix[:N1, :N1] = hessian[0][0].reshape(N1, N1)\n","        hessian_matrix[:N1, N1:N1+N2] = hessian[0][1].reshape(N1, N2)\n","        hessian_matrix[:N1, N1+N2:N1+N2+N3] = hessian[0][2].reshape(N1, N3)\n","        hessian_matrix[:N1, N1+N2+N3:N1+N2+N3+N4] = hessian[0][3].reshape(N1, N4)\n","        hessian_matrix[:N1, N1+N2+N3+N4:] = hessian[0][4].reshape(N1, N5)\n","\n","        hessian_matrix[N1:N1+N2, :N1] = hessian[1][0].reshape(N2, N1)\n","        hessian_matrix[N1:N1+N2, N1:N1+N2] = hessian[1][1].reshape(N2, N2)\n","        hessian_matrix[N1:N1+N2, N1+N2:N1+N2+N3] = hessian[1][2].reshape(N2, N3)\n","        hessian_matrix[N1:N1+N2, N1+N2+N3:N1+N2+N3+N4] = hessian[1][3].reshape(N2, N4)\n","        hessian_matrix[N1:N1+N2, N1+N2+N3+N4:] = hessian[1][4].reshape(N2, N5)\n","\n","        hessian_matrix[N1+N2:N1+N2+N3, :N1] = hessian[2][0].reshape(N3, N1)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1:N1+N2] = hessian[2][1].reshape(N3, N2)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1+N2:N1+N2+N3] = hessian[2][2].reshape(N3, N3)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1+N2+N3:N1+N2+N3+N4] = hessian[2][3].reshape(N3, N4)\n","        hessian_matrix[N1+N2:N1+N2+N3, N1+N2+N3+N4:] = hessian[2][4].reshape(N3, N5)\n","\n","        hessian_matrix[N1+N2+N3:N1+N2+N3+N4, :N1] = hessian[3][0].reshape(N4, N1)\n","        hessian_matrix[N1+N2+N3:N1+N2+N3+N4, N1:N1+N2] = hessian[3][1].reshape(N4, N2)\n","        hessian_matrix[N1+N2+N3:N1+N2+N3+N4, N1+N2:N1+N2+N3] = hessian[3][2].reshape(N4, N3)\n","        hessian_matrix[N1+N2+N3:N1+N2+N3+N4, N1+N2+N3:N1+N2+N3+N4] = hessian[3][3].reshape(N4, N4)\n","        hessian_matrix[N1+N2+N3:N1+N2+N3+N4, N1+N2+N3+N4:] = hessian[3][4].reshape(N4, N5)\n","\n","        hessian_matrix[N1+N2+N3+N4:, :N1] = hessian[4][0].reshape(N5, N1)\n","        hessian_matrix[N1+N2+N3+N4:, N1:N1+N2] = hessian[4][1].reshape(N5, N2)\n","        hessian_matrix[N1+N2+N3+N4:, N1+N2:N1+N2+N3] = hessian[4][2].reshape(N5, N3)\n","        hessian_matrix[N1+N2+N3+N4:, N1+N2+N3:N1+N2+N3+N4] = hessian[4][3].reshape(N5, N4)\n","        hessian_matrix[N1+N2+N3+N4:, N1+N2+N3+N4:] = hessian[4][4].reshape(N5, N5)\n","\n","    return hessian_matrix\n","\n","\n","def initialise_pc_activities(Ws, input, target):\n","    n_hidden = len(Ws)-1\n","    if n_hidden == 1:\n","        activities = [input, Ws[0]@input, target]\n","    if n_hidden == 2:\n","        activities = [input, Ws[0]@input, Ws[1]@Ws[0]@input, target]\n","    if n_hidden == 3:\n","        activities = [input, Ws[0]@input, Ws[1]@Ws[0]@input, Ws[2]@Ws[1]@Ws[0]@input, target]\n","    if n_hidden == 4:\n","        activities = [input, Ws[0]@input, Ws[1]@Ws[0]@input, Ws[2]@Ws[1]@Ws[0]@input, Ws[3]@Ws[2]@Ws[1]@Ws[0]@input, target]\n","    return activities\n","\n","\n","def compute_and_plot_hessian_metrics(model, input, target, init_type, save_dir):\n","    weights = model.get_weights()\n","    activities = initialise_pc_activities(Ws=weights, input=input, target=target)\n","\n","    hessian_matrix_frames, log_hessian_matrix_frames, hessian_eigenvals_frames = [], [], []\n","    for t in range(N_ITERS+1):\n","        if t in PLOT_ITERS:\n","            energy_hessian = compute_hessian(energy_fun)(\n","                weights,\n","                activities,\n","                n_iters=t,\n","                dt=DT\n","            )\n","            hessian_matrix = reshape_to_hessian_matrix(\n","                hessian=energy_hessian,\n","                weights=weights\n","            )\n","            fig = plot_hessian_matrix(\n","                hessian_matrix=hessian_matrix,\n","                title=f\"Inference iteration = {t}\",\n","                save_path=f\"{save_dir}/hessian_matrix_iter_{t}.pdf\"\n","            )\n","            hessian_matrix_frames.append(fig)\n","            fig = plot_hessian_matrix(\n","                hessian_matrix=hessian_matrix,\n","                log=True,\n","                title=f\"Inference iteration = {t}\",\n","                save_path=f\"{save_dir}/log_hessian_matrix_iter_{t}.pdf\"\n","            )\n","            log_hessian_matrix_frames.append(fig)\n","\n","            eigenvals, eigenvecs = eigh(hessian_matrix)\n","            fig = plot_hessian_eigenvalues(\n","                eigenvalues=eigenvals,\n","                title=f\"Inference iteration = {t}\",\n","                save_path=f\"{save_dir}/hessian_eigenvalues_iter_{t}.pdf\"\n","            )\n","            hessian_eigenvals_frames.append(fig)\n","\n","        if (t+1) == N_ITERS+1:\n","            print(f\"\\tmax Hessian eigenvalue: {eigenvals[0]}\")\n","            print(f\"\\tmin Hessian eigenvalue: {eigenvals[-1]}\\n\")\n","\n","    gif.save(\n","        frames=hessian_matrix_frames,\n","        path=f\"{save_dir}/hessian_matrix_infer_dynamics.gif\",\n","        duration=1,\n","        unit=\"s\"\n","    )\n","    gif.save(\n","        frames=log_hessian_matrix_frames,\n","        path=f\"{save_dir}/log_hessian_matrix_infer_dynamics.gif\",\n","        duration=1,\n","        unit=\"s\"\n","    )\n","    gif.save(\n","        frames=hessian_eigenvals_frames,\n","        path=f\"{save_dir}/hessian_eigenvalues_infer_dynamics.gif\",\n","        duration=1,\n","        unit=\"s\"\n","    )\n","    if init_type == \"origin\":\n","        theory_eigenvals = compute_theoretical_energy_eigenvals(\n","            model=model,\n","            X=input,\n","            Y=target\n","        )\n","    else:\n","        theory_eigenvals = None\n","    return eigenvals, theory_eigenvals, np.array(eigenvecs)\n","\n","\n","def compute_theoretical_energy_eigenvals(model, X, Y):\n","    n_params = model.n_params\n","    width = model.network[0][0].out_features\n","    theory_hessian_at_origin = np.zeros((n_params, n_params))\n","    output_dim = Y.shape[0]\n","\n","    sigma_yy = (Y@Y.T) / BATCH_SIZE\n","    d2F_dWL2 = - np.kron(sigma_yy, np.identity(width))\n","    theory_hessian_at_origin[-output_dim*width:, -output_dim*width:] = d2F_dWL2\n","\n","    n_hidden = len(model.network)-1\n","    if n_hidden == 1:\n","        input_dim = X.shape[0]\n","        sigma_xy = (X@Y.T) / BATCH_SIZE\n","        d2F_dW1dW2 = - np.kron(sigma_xy, np.identity(width))\n","        theory_hessian_at_origin[:input_dim*width, input_dim*width:] = d2F_dW1dW2\n","        theory_hessian_at_origin[input_dim*width:, :input_dim*width] = d2F_dW1dW2.T\n","\n","    theory_eigenvals, _ = eigh(theory_hessian_at_origin)\n","\n","    return theory_eigenvals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"zCfc_18QnDCv"},"outputs":[],"source":["#@title Landscape plotting\n","\n","\n","@gif.frame\n","def plot_objective_surface(\n","        objective_mesh: np.ndarray,\n","        weights: Tuple[np.ndarray, np.ndarray],\n","        objective_name: str,\n","        save_path: str,\n","        inference_iter: Optional[int] = None,\n","        tot_objective_max: Optional[float] = None,\n","        show_background: bool = True\n","    ) -> go.Figure():\n","    objective_notation = \"L\" if objective_name == \"loss\" else \"F\"\n","    objective_max, objective_min = objective_mesh.max(), objective_mesh.min()\n","    min_max_diff = objective_max - objective_min\n","    fig = go.Figure(\n","        data=go.Surface(\n","            z=objective_mesh,\n","            x=weights[0],\n","            y=weights[1],\n","            colorscale=COLORSCALE,\n","            colorbar=dict(\n","                title=f\"$\\LARGE{{\\mathcal{{{objective_notation}}}}}$\",\n","                x=0.85,\n","                y=0.57,\n","                len=0.3,\n","                titleside=\"right\",\n","                tickfont=dict(size=16),\n","                tickvals=[objective_min, objective_max],\n","                ticktext=[\"Low\" if min_max_diff > 0.1 else \"\", \"High\" if min_max_diff > 0.1 else \"\"]\n","            )\n","        )\n","    )\n","    fig.update_traces(\n","        contours_z=dict(\n","            show=True,\n","            usecolormap=True,\n","            highlightcolor=\"limegreen\",\n","            project_z=True if show_background else False,\n","        )\n","    )\n","    fig.update_layout(\n","        scene=dict(zaxis=(dict(\n","            title=\"\",\n","            range=[0, tot_objective_max*2 if tot_objective_max is not None else objective_max*2],\n","            showticklabels=False\n","        ))),\n","        font=dict(size=16),\n","        height=600,\n","        width=700,\n","        margin=dict(r=30, b=10, l=0, t=40),\n","        scene_aspectmode=\"cube\"\n","    )\n","    if show_background:\n","        title = f\"Inference iteration: {inference_iter}\" if inference_iter is not None else \"\"\n","        fig.update_layout(\n","            scene=dict(\n","                xaxis=dict(title=\"\", nticks=3, autorange=\"reversed\"),\n","                yaxis=dict(title=\"\", nticks=3, autorange=\"reversed\"),\n","            ),\n","            scene_camera=dict(\n","                center=dict(x=0.05, y=0.2, z=0),\n","                eye=dict(x=1.4, y=1.4, z=1.25)\n","            ),\n","            title=dict(\n","                text=title,\n","                y=0.95,\n","                x=0.42,\n","                xanchor=\"center\",\n","                yanchor=\"top\"\n","            )\n","        )\n","    else:\n","        fig.update_layout(\n","            scene=dict(\n","                xaxis=dict(\n","                    title=\"\",\n","                    autorange=\"reversed\",\n","                    showticklabels=False,\n","                    showbackground=False,\n","                ),\n","                yaxis=dict(\n","                    title=\"\",\n","                    autorange=\"reversed\",\n","                    showticklabels=False,\n","                    showbackground=False,\n","                ),\n","                zaxis=dict(showbackground=False)\n","            ),\n","            scene_camera=dict(\n","                center=dict(x=0.2, y=0.15, z=0),\n","                eye=dict(x=1.3, y=1.3, z=1)\n","            ),\n","        )\n","\n","    fig.write_image(save_path)\n","    return fig\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"1AeLLiT7kg6d"},"outputs":[],"source":["#@title Projection visualisations\n","\n","\n","def visualise_2D_loss_projections(\n","        model,\n","        input,\n","        target,\n","        domain,\n","        device,\n","        save_dir,\n","        hessian_eigenvecs = None\n","    ):\n","    input = torch.Tensor(input.T).to(device)\n","    target = torch.Tensor(target.T).to(device)\n","\n","    n_directions = 2\n","    if hessian_eigenvecs is None:\n","        random_directions = []\n","        for i in range(n_directions):\n","            random_direction = create_random_weight_direction(\n","                net=model.network,\n","                device=device\n","            )\n","            random_direction = [w for w in random_direction if len(w.shape) > 1]\n","            random_directions.append(random_direction)\n","    else:\n","        hessian_eigenvecs = torch.Tensor(np.array(hessian_eigenvecs)).to(device)\n","\n","    scaling_factors = [\n","        np.linspace(\n","            -domain, domain, SAMPLING_RESOLUTION\n","        ) for d in range(n_directions)\n","    ]\n","\n","    loss_fn = nn.MSELoss()\n","    loss_mesh = np.zeros((SAMPLING_RESOLUTION, SAMPLING_RESOLUTION))\n","    for j, a in enumerate(scaling_factors[0]):\n","        for i, b in enumerate(scaling_factors[1]):\n","\n","            if hessian_eigenvecs is None:\n","                n = 0\n","                for p in model.parameters():\n","                    if len(p.shape) > 1:\n","                        p.data = p.data + (a * random_directions[0][n]) + (b * random_directions[1][n])\n","                        n += 1\n","            else:\n","                param_vec = torch.cat(\n","                    [torch.flatten(p) for p in model.parameters() if len(p.shape) > 1]\n","                ).to(device)\n","                param_vec = param_vec + (a * hessian_eigenvecs[0]) + (b * hessian_eigenvecs[-1])\n","                vector_to_parameters(param_vec, model.parameters())\n","\n","            preds = model.forward(input)\n","            loss = loss_fn(preds, target)\n","            loss_mesh[i, j] = loss\n","\n","    directions_type = \"random\" if hessian_eigenvecs is None else \"hessian\"\n","    plot_objective_surface(\n","        objective_mesh=loss_mesh,\n","        weights=scaling_factors,\n","        objective_name=\"loss\",\n","        save_path=f\"{save_dir}/{directions_type}_surface_{domain}.pdf\"\n","    )\n","\n","\n","def visualise_2D_energy_projections(\n","        model,\n","        input,\n","        target,\n","        domain,\n","        device,\n","        save_dir,\n","        hessian_eigenvecs = None\n","    ):\n","    input = torch.Tensor(input.T).to(device)\n","    target = torch.Tensor(target.T).to(device)\n","\n","    n_directions = 2\n","    random_directions = []\n","    for i in range(n_directions):\n","        random_direction = create_random_weight_direction(\n","            net=model.network,\n","            device=device\n","        )\n","        random_direction = [w for w in random_direction if len(w.shape) > 1]\n","        random_directions.append(random_direction)\n","\n","    if hessian_eigenvecs is not None:\n","        hessian_eigenvecs = torch.Tensor(np.array(hessian_eigenvecs)).to(device)\n","\n","    scaling_factors = [\n","        np.linspace(\n","            -domain, domain, SAMPLING_RESOLUTION\n","        ) for d in range(n_directions)\n","    ]\n","\n","    loss_fn = nn.MSELoss()\n","    energy_mesh = np.zeros((SAMPLING_RESOLUTION, SAMPLING_RESOLUTION, N_ITERS+1))\n","    for j, a in enumerate(scaling_factors[0]):\n","        for i, b in enumerate(scaling_factors[1]):\n","\n","            if hessian_eigenvecs is None:\n","                n = 0\n","                for p in model.parameters():\n","                    if len(p.shape) > 1:\n","                        p.data = p.data + (a * random_directions[0][n]) + (b * random_directions[1][n])\n","                        n += 1\n","            else:\n","                param_vec = torch.cat(\n","                    [torch.flatten(p) for p in model.parameters() if len(p.shape) > 1]\n","                ).to(device)\n","                param_vec = param_vec + (a * hessian_eigenvecs[0]) + (b * hessian_eigenvecs[-1])\n","                vector_to_parameters(param_vec, model.parameters())\n","\n","            preds = model.forward(input)\n","            loss = loss_fn(preds, target)\n","            energy_mesh[i, j, 0] = loss\n","\n","            tot_energy_iters = model.infer_train(\n","                obs=target,\n","                prior=input,\n","                n_iters=N_ITERS\n","            )\n","            if len(tot_energy_iters) != N_ITERS:\n","                n_missing_iters = N_ITERS - len(tot_energy_iters)\n","                tot_energy_iters.extend([tot_energy_iters[-1]]*n_missing_iters)\n","\n","            energy_mesh[i, j, 1:] = tot_energy_iters\n","\n","    energy_surface_frames = []\n","    directions_type = \"random\" if hessian_eigenvecs is None else \"hessian\"\n","    energy_iters_max = energy_mesh.max()\n","    for t in range(N_ITERS+1):\n","        if t in PLOT_ITERS:\n","            fig = plot_objective_surface(\n","                objective_mesh=energy_mesh[:, :, t],\n","                weights=scaling_factors,\n","                objective_name=\"energy\",\n","                inference_iter=t,\n","                tot_objective_max=energy_iters_max,\n","                save_path=f\"{save_dir}/{directions_type}_surface_{domain}_iter_{t}.pdf\"\n","            )\n","            energy_surface_frames.append(fig)\n","\n","    gif.save(\n","        energy_surface_frames,\n","        f\"{save_dir}/{directions_type}_surface_{domain}_dynamics.gif\",\n","        duration=1,\n","        unit=\"s\"\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"U3Td0mTf9C3q"},"source":["## Scripts"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"CG_cBy23tCN6"},"outputs":[],"source":["#@title Loss Hessian Analysis\n","\n","\n","def analyse_loss_hessian(dataset, data_dim, n_hidden, width, init_type, seed, save_dir):\n","    print(\"\\tAnalysing loss Hessian at the origin...\")\n","    set_seed(seed)\n","    device = get_device()\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    input, target = get_dataset_sample(\n","        dataset_id=dataset,\n","        data_dim=data_dim,\n","        n_hidden=n_hidden\n","    )\n","    network = get_fc_network(\n","        input_dim=input.shape[0],\n","        n_hidden=n_hidden,\n","        width=width,\n","        act_fn=\"linear\",\n","        output_dim=target.shape[0]\n","    )\n","    model = BPN(network=network).to(device)\n","    init_weights(model=model, init_type=init_type)\n","\n","    # compute and plot Hessian matrix\n","    weights = model.get_weights()\n","    loss_hessian = compute_hessian(mse_loss_fun)(\n","        weights,\n","        input,\n","        target\n","    )\n","    hessian_matrix = reshape_to_hessian_matrix(\n","        hessian=loss_hessian,\n","        weights=weights\n","    )\n","    plot_hessian_matrix(\n","        hessian_matrix=hessian_matrix,\n","        save_path=f\"{save_dir}/hessian_matrix.pdf\"\n","    )\n","    hessian_eigenvals, hessian_eigenvecs = eigh(hessian_matrix)\n","    print(f\"\\tmax Hessian eigenvalue: {hessian_eigenvals[0]}\")\n","    print(f\"\\tmin Hessian eigenvalue: {hessian_eigenvals[-1]}\")\n","    hessian_eigenvals = hessian_eigenvals+1e-3 if dataset == \"MNIST-1D\" and n_hidden > 2 else hessian_eigenvals\n","    plot_hessian_eigenvalues(\n","        eigenvalues=hessian_eigenvals,\n","        save_path=f\"{save_dir}/hessian_eigenvalues.pdf\"\n","    )\n","    if dataset == \"toy_gaussian\" and n_hidden == 3 and width == 4:\n","        # plot landscape projected onto Hessian max and min eigenvectors\n","        for domain in DOMAINS:\n","            visualise_2D_loss_projections(\n","                model=model,\n","                input=input,\n","                target=target,\n","                domain=domain,\n","                device=device,\n","                save_dir=save_dir,\n","                hessian_eigenvecs=hessian_eigenvecs\n","            )\n","\n","    return hessian_eigenvals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"4SYNS19FAyCO"},"outputs":[],"source":["#@title Energy Hessian Analysis\n","\n","\n","def analyse_energy_hessian(dataset, data_dim, n_hidden, width, init_type, seed, save_dir):\n","    print(\"\\n\\tAnalysing energy Hessian at the origin...\")\n","    set_seed(seed)\n","    device = get_device()\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    input, target = get_dataset_sample(\n","        dataset_id=dataset,\n","        data_dim=data_dim,\n","        n_hidden=n_hidden\n","    )\n","    network = get_fc_network(\n","        input_dim=input.shape[0],\n","        n_hidden=n_hidden,\n","        width=width,\n","        act_fn=\"linear\",\n","        output_dim=target.shape[0]\n","    )\n","    model = PCN(network=network, dt=DT, device=device)\n","    init_weights(model=model, init_type=init_type)\n","\n","    # compute and plot Hessian matrix\n","    numeric_hessian_eigenvals, theory_hessian_eigenvals, hessian_eigenvecs = compute_and_plot_hessian_metrics(\n","        model=model,\n","        input=input,\n","        target=target,\n","        init_type=init_type,\n","        save_dir=save_dir\n","    )\n","\n","    if dataset == \"toy_gaussian\" and n_hidden == 3 and width == 4:\n","        # plot landscape projected onto Hessian max and min eigenvectors\n","        for domain in DOMAINS:\n","            visualise_2D_energy_projections(\n","                model=model,\n","                input=input,\n","                target=target,\n","                domain=domain,\n","                device=device,\n","                save_dir=save_dir,\n","                hessian_eigenvecs=hessian_eigenvecs\n","            )\n","\n","    return numeric_hessian_eigenvals, theory_hessian_eigenvals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"MC9YHy36N5XJ"},"outputs":[],"source":["#@title Main script\n","\n","\n","def run_hessian_analysis():\n","    for dataset in DATASETS:\n","        for n_hidden, width in N_HIDDEN_WIDTHS[dataset]:\n","            data_dim = get_data_dim(dataset=dataset, n_hidden=n_hidden)\n","            for init_type in INIT_TYPES[n_hidden]:\n","                for seed in range(N_SEEDS):\n","                    experiment_dir = setup_experiment(\n","                        results_dir=RESULTS_DIR,\n","                        dataset=dataset,\n","                        data_dim=data_dim,\n","                        n_hidden=n_hidden,\n","                        width=width,\n","                        init_type=init_type,\n","                        seed=seed,\n","                    )\n","                    loss_hessian_eigenvals = analyse_loss_hessian(\n","                        dataset=dataset,\n","                        data_dim=data_dim,\n","                        n_hidden=n_hidden,\n","                        width=width,\n","                        init_type=init_type,\n","                        seed=seed,\n","                        save_dir=f\"{experiment_dir}/bp\"\n","                    )\n","                    energy_hessian_eigenvals, theory_energy_hessian_eigenvals = analyse_energy_hessian(\n","                        dataset=dataset,\n","                        data_dim=data_dim,\n","                        n_hidden=n_hidden,\n","                        width=width,\n","                        init_type=init_type,\n","                        seed=seed,\n","                        save_dir=f\"{experiment_dir}/pc\"\n","                    )\n","                    np.save(\"loss_eigens.npy\", loss_hessian_eigenvals)\n","                    np.save(\"energy_eigens.npy\", energy_hessian_eigenvals)\n","                    np.save(\"theory_energy_eigens.npy\", theory_energy_hessian_eigenvals)\n","                    plot_loss_and_energy_hessian_eigenvals(\n","                        hessian_eigenvals=[\n","                            loss_hessian_eigenvals,\n","                            energy_hessian_eigenvals,\n","                            theory_energy_hessian_eigenvals\n","                        ],\n","                        n_hidden=n_hidden,\n","                        dataset=dataset,\n","                        save_path=f\"{experiment_dir}/hessian_eigenspectrum.pdf\"\n","                    )\n"]},{"cell_type":"markdown","metadata":{"id":"GbFjLmSIVT3F"},"source":["## Run analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-f6nKL2rOJrn"},"outputs":[],"source":["run_hessian_analysis()\n","!zip -r DLNs_hessian_results.zip results"]},{"cell_type":"markdown","metadata":{"id":"1IzwabwxWlEV"},"source":["## Download results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22764,"status":"ok","timestamp":1716205992700,"user":{"displayName":"Francesco Innocenti","userId":"11758167882892285303"},"user_tz":-60},"id":"VXcKCAuTaM3H","outputId":"a1e6b133-f60b-47c8-faa6-4f6fea3d4ce1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import shutil\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvyPWf0qWnqb"},"outputs":[],"source":["%%capture\n","!zip -r /content/linear_fashion_depth_10.zip /content/results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716205992700,"user":{"displayName":"Francesco Innocenti","userId":"11758167882892285303"},"user_tz":-60},"id":"L_5laoq5aRr6","outputId":"d731d1d6-e390-47dd-a83c-2e855dac1555"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/DLNs_hessian_results.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["colab_link = \"/content/DLNs_hessian_results.zip\"\n","gdrive_link = \"/content/drive/MyDrive/\"\n","shutil.copy(colab_link, gdrive_link)"]}],"metadata":{"colab":{"collapsed_sections":["tiGklA_e9Abi","U3Td0mTf9C3q","1IzwabwxWlEV"],"provenance":[{"file_id":"1H8dlrCte8acQ3s6ft68Un1qe8QfLGl8R","timestamp":1713105733754}],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}